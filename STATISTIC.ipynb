{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical techniques for forecasting \n",
    "\n",
    "We try to find the best-fit combination of the parameters by Auto-ARIMA and we use those parameters in the VARMA model for predicting the forecast values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX, VARMAXResults\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pmdarima import auto_arima\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = 'data_feed/'\n",
    "# Set the hyperparameters\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_EPOCHS = 100\n",
    "LAG = 10\n",
    "N_STOCK = 20\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data_feed directory exist if not \n",
    "assert os.path.exists(BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all the files in the data_feed directory\n",
    "files = os.listdir('data_feed/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df: pd.DataFrame, file_name: str) -> None:\n",
    "    \"\"\"\n",
    "    modify columns names (exept date) into the following structure: \n",
    "        *column_name*_*stock_name* \n",
    "        \n",
    "    Example: Open_AAPL\n",
    "    \"\"\"\n",
    "    df.rename(columns=dict(zip(df.columns[1:], df.columns[1:] + '_' + file_name[:-4])), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read First File into a pandas dataframe\n",
    "df = pd.read_csv(BASE_DIR+files[0])\n",
    "rename_columns(df, files[0])\n",
    "\n",
    "# Merge Everything into a unique DataFrame\n",
    "for fn in files[1:]:\n",
    "    df2 = pd.read_csv(BASE_DIR+fn)\n",
    "    rename_columns(df2, fn)\n",
    "    result = df.merge(df2, on='Date')\n",
    "    df = result\n",
    "\n",
    "df.set_index('Date',inplace=True)\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if \"Adj Close\" in col]\n",
    "df = df[cols]\n",
    "\n",
    "df_copy = df.copy(deep=True)\n",
    "for col in df.columns:\n",
    "    df_copy[f'Ret_{col}'] = df_copy[col] / df_copy[col].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = df.index[0] + pd.offsets.DateOffset(years=8)\n",
    "train_data = df[df.index <= split_date]\n",
    "test_data = df[df.index > split_date]\n",
    "#test_data.to_csv('TEST.csv')\n",
    "#train_data.to_csv('TRAIN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(train_data.values)\n",
    "scaled_test = scaler.transform(test_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesdataset(Dataset):\n",
    "    def __init__(self, lag: int, data: np.ndarray, device: torch.device):\n",
    "        self.lag = lag\n",
    "        self.data = data\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        lenght = len(self.data)\n",
    "        return lenght - (self.lag + 1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx:idx+self.lag, :].flatten()\n",
    "        Y = self.data[idx+self.lag, :]\n",
    "        return torch.Tensor(X, device=self.device), torch.Tensor(Y, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesdataset(lag=LAG, data=scaled_train, device=device)\n",
    "test_dataset = TimeSeriesdataset(lag=LAG, data=scaled_test, device=device)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Auto_ARIMA and VARMA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`auto_arima` is a function used in time series analysis to automatically determine the optimal parameters for an ARIMA (AutoRegressive Integrated MovingAverage) model. ARIMA models are commonly used to forecast future values based on past observations.\n",
    "The `auto_arima` function uses an iterative approach to search for the best combination of parameters (p, d, q) for the ARIMA model.\n",
    "- `p` represents the order of the AutoRegressive (AR) component, which captures the linear relationship between an observation and some number of lagged observations.\n",
    "- `d` represents the order of differencing required to make the time series stationary. Differencing removes trends and seasonality from the data.\n",
    "- `q` represents the order of the Moving Average (MA) component, which models the dependency between an observation and a residual error from a moving average of lagged observations.\n",
    "\n",
    "By automatically determining the optimal parameters, `auto_arima` simplifies the process of fitting an ARIMA model to time series data and helps in generating more accurate forecasts."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`VARMA` is an acronym for Vector Autoregressive Moving Average. It is a statistical model used for analyzing and forecasting multivariate time series data. The advantage is that VARMA models can handle multiple time series variables simultaneously.\n",
    "VARMA models combine autoregressive (AR) and moving average (MA) components to capture the linear relationships and dependencies among the variables. The \"vector\" in VARMA refers to the fact that each variable is modeled as a linear combination of lagged values of all variables in the system.\n",
    "\n",
    "VARMA models require specifying two sets of parameters:\n",
    "- `p` and `q` represent the orders of the autoregressive and moving average components, respectively, for each variable in the system.\n",
    "- Additionally, VARMA models also involve specifying the lag order for the error terms of each equation.\n",
    "VARMA models are useful for analyzing the dynamic relationships between multiple time series variables and can provide forecasts for each variable in the system based on historical data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our project, we have used `auto_arima` to automatically select the optimal parameters for an ARIMA model, and then used VARMA with the same parameters to analyze and perform forecasting on multiple time series variables simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
    "    \n",
    "    def mean_absolute_percentage_error(y_true, y_pred): \n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print('Evaluation metric results:-')\n",
    "    print(f'MSE is : {metrics.mean_squared_error(y_true, y_pred)}')\n",
    "    print(f'MAE is : {metrics.mean_absolute_error(y_true, y_pred)}')\n",
    "    print(f'RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}')\n",
    "    print(f'MAPE is : {mean_absolute_percentage_error(y_true, y_pred)}')\n",
    "    print(f'R2 is : {metrics.r2_score(y_true, y_pred)}',end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Augmented_Dickey_Fuller_Test_func(series , column_name):\n",
    "    print (f'Results of Dickey-Fuller Test for column: {column_name}')\n",
    "    dftest = adfuller(series, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','No Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "       dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)\n",
    "    if dftest[1] <= 0.05:\n",
    "        print(\"Conclusion:====> Reject the null hypothesis: Data is stationary\")\n",
    "    else:\n",
    "        print(\"Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Dickey-Fuller Test for column: Adj Close_AAPL\n",
      "Test Statistic                    0.410100\n",
      "p-value                           0.981869\n",
      "No Lags Used                     22.000000\n",
      "Number of Observations Used    2589.000000\n",
      "Critical Value (1%)              -3.432878\n",
      "Critical Value (5%)              -2.862657\n",
      "Critical Value (10%)             -2.567365\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_AMZN\n",
      "Test Statistic                   -1.066050\n",
      "p-value                           0.728419\n",
      "No Lags Used                     27.000000\n",
      "Number of Observations Used    2584.000000\n",
      "Critical Value (1%)              -3.432883\n",
      "Critical Value (5%)              -2.862659\n",
      "Critical Value (10%)             -2.567366\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_BRK-A\n",
      "Test Statistic                   -0.180345\n",
      "p-value                           0.940824\n",
      "No Lags Used                     27.000000\n",
      "Number of Observations Used    2584.000000\n",
      "Critical Value (1%)              -3.432883\n",
      "Critical Value (5%)              -2.862659\n",
      "Critical Value (10%)             -2.567366\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_DIS\n",
      "Test Statistic                   -2.154635\n",
      "p-value                           0.223120\n",
      "No Lags Used                     24.000000\n",
      "Number of Observations Used    2587.000000\n",
      "Critical Value (1%)              -3.432880\n",
      "Critical Value (5%)              -2.862658\n",
      "Critical Value (10%)             -2.567365\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_GOOGL\n",
      "Test Statistic                   -0.297889\n",
      "p-value                           0.925803\n",
      "No Lags Used                     23.000000\n",
      "Number of Observations Used    2588.000000\n",
      "Critical Value (1%)              -3.432879\n",
      "Critical Value (5%)              -2.862657\n",
      "Critical Value (10%)             -2.567365\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_HD\n",
      "Test Statistic                   -0.872026\n",
      "p-value                           0.797045\n",
      "No Lags Used                      9.000000\n",
      "Number of Observations Used    2602.000000\n",
      "Critical Value (1%)              -3.432866\n",
      "Critical Value (5%)              -2.862651\n",
      "Critical Value (10%)             -2.567362\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_JNJ\n",
      "Test Statistic                   -1.354783\n",
      "p-value                           0.603751\n",
      "No Lags Used                     10.000000\n",
      "Number of Observations Used    2601.000000\n",
      "Critical Value (1%)              -3.432867\n",
      "Critical Value (5%)              -2.862652\n",
      "Critical Value (10%)             -2.567362\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_JPM\n",
      "Test Statistic                   -0.917163\n",
      "p-value                           0.782268\n",
      "No Lags Used                     19.000000\n",
      "Number of Observations Used    2592.000000\n",
      "Critical Value (1%)              -3.432875\n",
      "Critical Value (5%)              -2.862656\n",
      "Critical Value (10%)             -2.567364\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_KO\n",
      "Test Statistic                   -0.487266\n",
      "p-value                           0.894478\n",
      "No Lags Used                     12.000000\n",
      "Number of Observations Used    2599.000000\n",
      "Critical Value (1%)              -3.432869\n",
      "Critical Value (5%)              -2.862653\n",
      "Critical Value (10%)             -2.567362\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_MA\n",
      "Test Statistic                   -0.243454\n",
      "p-value                           0.933140\n",
      "No Lags Used                     28.000000\n",
      "Number of Observations Used    2583.000000\n",
      "Critical Value (1%)              -3.432884\n",
      "Critical Value (5%)              -2.862660\n",
      "Critical Value (10%)             -2.567366\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_MCD\n",
      "Test Statistic                    0.618135\n",
      "p-value                           0.988054\n",
      "No Lags Used                     27.000000\n",
      "Number of Observations Used    2584.000000\n",
      "Critical Value (1%)              -3.432883\n",
      "Critical Value (5%)              -2.862659\n",
      "Critical Value (10%)             -2.567366\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_META\n",
      "Test Statistic                   -1.598573\n",
      "p-value                           0.484310\n",
      "No Lags Used                     20.000000\n",
      "Number of Observations Used    2591.000000\n",
      "Critical Value (1%)              -3.432876\n",
      "Critical Value (5%)              -2.862656\n",
      "Critical Value (10%)             -2.567364\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_MSFT\n",
      "Test Statistic                    0.668098\n",
      "p-value                           0.989179\n",
      "No Lags Used                     17.000000\n",
      "Number of Observations Used    2594.000000\n",
      "Critical Value (1%)              -3.432873\n",
      "Critical Value (5%)              -2.862655\n",
      "Critical Value (10%)             -2.567363\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_NKE\n",
      "Test Statistic                   -1.206300\n",
      "p-value                           0.670880\n",
      "No Lags Used                     25.000000\n",
      "Number of Observations Used    2586.000000\n",
      "Critical Value (1%)              -3.432881\n",
      "Critical Value (5%)              -2.862658\n",
      "Critical Value (10%)             -2.567365\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_PFE\n",
      "Test Statistic                   -1.594742\n",
      "p-value                           0.486234\n",
      "No Lags Used                     27.000000\n",
      "Number of Observations Used    2584.000000\n",
      "Critical Value (1%)              -3.432883\n",
      "Critical Value (5%)              -2.862659\n",
      "Critical Value (10%)             -2.567366\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_PG\n",
      "Test Statistic                   -0.155200\n",
      "p-value                           0.943655\n",
      "No Lags Used                     18.000000\n",
      "Number of Observations Used    2593.000000\n",
      "Critical Value (1%)              -3.432874\n",
      "Critical Value (5%)              -2.862655\n",
      "Critical Value (10%)             -2.567364\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_UNH\n",
      "Test Statistic                    0.308575\n",
      "p-value                           0.977735\n",
      "No Lags Used                     22.000000\n",
      "Number of Observations Used    2589.000000\n",
      "Critical Value (1%)              -3.432878\n",
      "Critical Value (5%)              -2.862657\n",
      "Critical Value (10%)             -2.567365\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_V\n",
      "Test Statistic                   -0.363263\n",
      "p-value                           0.916054\n",
      "No Lags Used                     27.000000\n",
      "Number of Observations Used    2584.000000\n",
      "Critical Value (1%)              -3.432883\n",
      "Critical Value (5%)              -2.862659\n",
      "Critical Value (10%)             -2.567366\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_WMT\n",
      "Test Statistic                   -0.422038\n",
      "p-value                           0.906354\n",
      "No Lags Used                      9.000000\n",
      "Number of Observations Used    2602.000000\n",
      "Critical Value (1%)              -3.432866\n",
      "Critical Value (5%)              -2.862651\n",
      "Critical Value (10%)             -2.567362\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_XOM\n",
      "Test Statistic                   -0.183921\n",
      "p-value                           0.940411\n",
      "No Lags Used                     28.000000\n",
      "Number of Observations Used    2583.000000\n",
      "Critical Value (1%)              -3.432884\n",
      "Critical Value (5%)              -2.862660\n",
      "Critical Value (10%)             -2.567366\n",
      "dtype: float64\n",
      "Conclusion:====> Fail to reject the null hypothesis: Data is non-stationary\n"
     ]
    }
   ],
   "source": [
    "df_stat = pd.DataFrame(df)\n",
    "\n",
    "for column in df.columns:\n",
    "    Augmented_Dickey_Fuller_Test_func(df[column].values,column)\n",
    "    #df_stat[column] = stationarity_test(df[column].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.diff()\n",
    "train_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Dickey-Fuller Test for column: Adj Close_AAPL\n",
      "Test Statistic                -8.868298e+00\n",
      "p-value                        1.420554e-14\n",
      "No Lags Used                   2.600000e+01\n",
      "Number of Observations Used    1.987000e+03\n",
      "Critical Value (1%)           -3.433645e+00\n",
      "Critical Value (5%)           -2.862996e+00\n",
      "Critical Value (10%)          -2.567545e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_AMZN\n",
      "Test Statistic                -9.626434e+00\n",
      "p-value                        1.655871e-16\n",
      "No Lags Used                   2.600000e+01\n",
      "Number of Observations Used    1.987000e+03\n",
      "Critical Value (1%)           -3.433645e+00\n",
      "Critical Value (5%)           -2.862996e+00\n",
      "Critical Value (10%)          -2.567545e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_BRK-A\n",
      "Test Statistic                -1.095695e+01\n",
      "p-value                        8.514698e-20\n",
      "No Lags Used                   2.300000e+01\n",
      "Number of Observations Used    1.990000e+03\n",
      "Critical Value (1%)           -3.433640e+00\n",
      "Critical Value (5%)           -2.862993e+00\n",
      "Critical Value (10%)          -2.567544e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_DIS\n",
      "Test Statistic                -1.079793e+01\n",
      "p-value                        2.052727e-19\n",
      "No Lags Used                   1.100000e+01\n",
      "Number of Observations Used    2.002000e+03\n",
      "Critical Value (1%)           -3.433621e+00\n",
      "Critical Value (5%)           -2.862985e+00\n",
      "Critical Value (10%)          -2.567539e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_GOOGL\n",
      "Test Statistic                -9.876504e+00\n",
      "p-value                        3.869817e-17\n",
      "No Lags Used                   2.200000e+01\n",
      "Number of Observations Used    1.991000e+03\n",
      "Critical Value (1%)           -3.433639e+00\n",
      "Critical Value (5%)           -2.862993e+00\n",
      "Critical Value (10%)          -2.567543e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_HD\n",
      "Test Statistic                -1.523020e+01\n",
      "p-value                        5.334566e-28\n",
      "No Lags Used                   8.000000e+00\n",
      "Number of Observations Used    2.005000e+03\n",
      "Critical Value (1%)           -3.433616e+00\n",
      "Critical Value (5%)           -2.862983e+00\n",
      "Critical Value (10%)          -2.567538e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_JNJ\n",
      "Test Statistic                -1.349763e+01\n",
      "p-value                        3.020158e-25\n",
      "No Lags Used                   1.200000e+01\n",
      "Number of Observations Used    2.001000e+03\n",
      "Critical Value (1%)           -3.433622e+00\n",
      "Critical Value (5%)           -2.862985e+00\n",
      "Critical Value (10%)          -2.567540e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_JPM\n",
      "Test Statistic                -8.467904e+00\n",
      "p-value                        1.504991e-13\n",
      "No Lags Used                   2.600000e+01\n",
      "Number of Observations Used    1.987000e+03\n",
      "Critical Value (1%)           -3.433645e+00\n",
      "Critical Value (5%)           -2.862996e+00\n",
      "Critical Value (10%)          -2.567545e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_KO\n",
      "Test Statistic                -1.396747e+01\n",
      "p-value                        4.406407e-26\n",
      "No Lags Used                   1.200000e+01\n",
      "Number of Observations Used    2.001000e+03\n",
      "Critical Value (1%)           -3.433622e+00\n",
      "Critical Value (5%)           -2.862985e+00\n",
      "Critical Value (10%)          -2.567540e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_MA\n",
      "Test Statistic                -9.906146e+00\n",
      "p-value                        3.259618e-17\n",
      "No Lags Used                   2.500000e+01\n",
      "Number of Observations Used    1.988000e+03\n",
      "Critical Value (1%)           -3.433644e+00\n",
      "Critical Value (5%)           -2.862995e+00\n",
      "Critical Value (10%)          -2.567545e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_MCD\n",
      "Test Statistic                -9.023284e+00\n",
      "p-value                        5.698641e-15\n",
      "No Lags Used                   2.600000e+01\n",
      "Number of Observations Used    1.987000e+03\n",
      "Critical Value (1%)           -3.433645e+00\n",
      "Critical Value (5%)           -2.862996e+00\n",
      "Critical Value (10%)          -2.567545e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_META\n",
      "Test Statistic                -8.808716e+00\n",
      "p-value                        2.018499e-14\n",
      "No Lags Used                   2.600000e+01\n",
      "Number of Observations Used    1.987000e+03\n",
      "Critical Value (1%)           -3.433645e+00\n",
      "Critical Value (5%)           -2.862996e+00\n",
      "Critical Value (10%)          -2.567545e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_MSFT\n",
      "Test Statistic                -1.195559e+01\n",
      "p-value                        4.217408e-22\n",
      "No Lags Used                   2.500000e+01\n",
      "Number of Observations Used    1.988000e+03\n",
      "Critical Value (1%)           -3.433644e+00\n",
      "Critical Value (5%)           -2.862995e+00\n",
      "Critical Value (10%)          -2.567545e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_NKE\n",
      "Test Statistic                -9.379901e+00\n",
      "p-value                        7.002840e-16\n",
      "No Lags Used                   2.200000e+01\n",
      "Number of Observations Used    1.991000e+03\n",
      "Critical Value (1%)           -3.433639e+00\n",
      "Critical Value (5%)           -2.862993e+00\n",
      "Critical Value (10%)          -2.567543e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_PFE\n",
      "Test Statistic                -9.847545e+00\n",
      "p-value                        4.576847e-17\n",
      "No Lags Used                   2.400000e+01\n",
      "Number of Observations Used    1.989000e+03\n",
      "Critical Value (1%)           -3.433642e+00\n",
      "Critical Value (5%)           -2.862994e+00\n",
      "Critical Value (10%)          -2.567544e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_PG\n",
      "Test Statistic                -1.232862e+01\n",
      "p-value                        6.503118e-23\n",
      "No Lags Used                   1.400000e+01\n",
      "Number of Observations Used    1.999000e+03\n",
      "Critical Value (1%)           -3.433625e+00\n",
      "Critical Value (5%)           -2.862987e+00\n",
      "Critical Value (10%)          -2.567540e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_UNH\n",
      "Test Statistic                -1.329577e+01\n",
      "p-value                        7.211251e-25\n",
      "No Lags Used                   1.400000e+01\n",
      "Number of Observations Used    1.999000e+03\n",
      "Critical Value (1%)           -3.433625e+00\n",
      "Critical Value (5%)           -2.862987e+00\n",
      "Critical Value (10%)          -2.567540e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_V\n",
      "Test Statistic                -8.542443e+00\n",
      "p-value                        9.701032e-14\n",
      "No Lags Used                   2.600000e+01\n",
      "Number of Observations Used    1.987000e+03\n",
      "Critical Value (1%)           -3.433645e+00\n",
      "Critical Value (5%)           -2.862996e+00\n",
      "Critical Value (10%)          -2.567545e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_WMT\n",
      "Test Statistic                -9.469954e+00\n",
      "p-value                        4.131836e-16\n",
      "No Lags Used                   2.300000e+01\n",
      "Number of Observations Used    1.990000e+03\n",
      "Critical Value (1%)           -3.433640e+00\n",
      "Critical Value (5%)           -2.862993e+00\n",
      "Critical Value (10%)          -2.567544e+00\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n",
      "Results of Dickey-Fuller Test for column: Adj Close_XOM\n",
      "Test Statistic                  -26.501255\n",
      "p-value                           0.000000\n",
      "No Lags Used                      2.000000\n",
      "Number of Observations Used    2011.000000\n",
      "Critical Value (1%)              -3.433606\n",
      "Critical Value (5%)              -2.862978\n",
      "Critical Value (10%)             -2.567536\n",
      "dtype: float64\n",
      "Conclusion:====> Reject the null hypothesis: Data is stationary\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    Augmented_Dickey_Fuller_Test_func(train_data[column].values,column)\n",
    "    #df_stat[column] = stationarity_test(df[column].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best orders using auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching order of p and q for : Adj Close_AAPL\n",
      "optimal order for:Adj Close_AAPL is: (3, 1, 0) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_AMZN\n",
      "optimal order for:Adj Close_AMZN is: (3, 0, 0) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_BRK-A\n",
      "optimal order for:Adj Close_BRK-A is: (3, 0, 2) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_DIS\n",
      "optimal order for:Adj Close_DIS is: (2, 0, 1) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_GOOGL\n",
      "optimal order for:Adj Close_GOOGL is: (1, 0, 0) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_HD\n",
      "optimal order for:Adj Close_HD is: (3, 0, 2) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_JNJ\n",
      "optimal order for:Adj Close_JNJ is: (2, 0, 3) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_JPM\n",
      "optimal order for:Adj Close_JPM is: (2, 0, 0) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_KO\n",
      "optimal order for:Adj Close_KO is: (2, 0, 3) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_MA\n",
      "optimal order for:Adj Close_MA is: (3, 0, 1) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_MCD\n",
      "optimal order for:Adj Close_MCD is: (3, 0, 2) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_META\n",
      "optimal order for:Adj Close_META is: (3, 0, 0) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_MSFT\n",
      "optimal order for:Adj Close_MSFT is: (3, 1, 0) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_NKE\n",
      "optimal order for:Adj Close_NKE is: (3, 0, 2) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_PFE\n",
      "optimal order for:Adj Close_PFE is: (1, 0, 0) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_PG\n",
      "optimal order for:Adj Close_PG is: (1, 0, 0) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_UNH\n",
      "optimal order for:Adj Close_UNH is: (3, 0, 2) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_V\n",
      "optimal order for:Adj Close_V is: (3, 0, 2) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_WMT\n",
      "optimal order for:Adj Close_WMT is: (1, 0, 0) \n",
      "\n",
      "\n",
      "Searching order of p and q for : Adj Close_XOM\n",
      "optimal order for:Adj Close_XOM is: (0, 0, 0) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pq = []\n",
    "max_pdq = 3\n",
    "for column in df.columns:\n",
    "    print(f'Searching order of p and q for : {column}')\n",
    "    #parameter = find_best_order_ARIMA(train_data[column].values, max_pdq)\n",
    "    stepwise_model = auto_arima(train_data[column].values, start_p=1, start_q=1, max_p=max_pdq, max_q=max_pdq, seasonal=False,\n",
    "        error_action='ignore',suppress_warnings=True, stepwise=True,maxiter=1000)\n",
    "    parameter = stepwise_model.get_params().get('order')\n",
    "    print(f'optimal order for:{column} is: {parameter} \\n\\n')\n",
    "    pq.append(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 2)\n",
      "3 2\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def valore_piu_frequente(lista):\n",
    "    conteggio = Counter(lista)\n",
    "    valore_piu_comune = conteggio.most_common(1)[0][0]\n",
    "    return valore_piu_comune\n",
    "\n",
    "best_order_pq = valore_piu_frequente(pq)\n",
    "print(best_order_pq)  \n",
    "print(best_order_pq[0], best_order_pq[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2014, 20)\n",
      "(597, 20)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply VARMAX using the most frequent 'best-order' pair of order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-0c6f868fedeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Apply VARMAX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVARMAX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_order_pq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_order_pq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_fit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[0mflags\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hessian_method'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim_hessian\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[0mfargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m             mlefit = super(MLEModel, self).fit(start_params, method=method,\n\u001b[0m\u001b[0;32m    705\u001b[0m                                                \u001b[0mfargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                                                \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m         xopt, retvals, optim_settings = optimizer._fit(f, score, start_params,\n\u001b[0m\u001b[0;32m    567\u001b[0m                                                        \u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m                                                        \u001b[0mhessian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\optimizer.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_funcs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         xopt, retvals = func(objective, gradient, start_params, fargs, kwargs,\n\u001b[0m\u001b[0;32m    243\u001b[0m                              \u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                              \u001b[0mretall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\optimizer.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[1;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m     retvals = optimize.fmin_l_bfgs_b(func, start_params, maxiter=maxiter,\n\u001b[0m\u001b[0;32m    660\u001b[0m                                      \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m                                      \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    197\u001b[0m             'maxls': maxls}\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0m\u001b[0;32m    200\u001b[0m                            **opts)\n\u001b[0;32m    201\u001b[0m     d = {'grad': res['jac'],\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    360\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_grad\u001b[1;34m()\u001b[0m\n\u001b[0;32m    171\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mngev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 self.g = approx_derivative(fun_wrapped, self.x, f0=self.f,\n\u001b[0m\u001b[0;32m    174\u001b[0m                                            **finite_diff_options)\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\optimize\\_numdiff.py\u001b[0m in \u001b[0;36mapprox_derivative\u001b[1;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msparsity\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m             return _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[0m\u001b[0;32m    506\u001b[0m                                      use_one_sided, method)\n\u001b[0;32m    507\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\optimize\\_numdiff.py\u001b[0m in \u001b[0;36m_dense_difference\u001b[1;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[0mdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Recompute dx as exactly representable number.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'3-point'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0muse_one_sided\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\optimize\\_numdiff.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m             raise RuntimeError(\"`fun` return value has \"\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m             \u001b[1;31m# Make sure the function returns a true scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(params, *args)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloglike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py\u001b[0m in \u001b[0;36mloglike\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    937\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'inversion_method'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mINVERT_UNIVARIATE\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mSOLVE_LU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 939\u001b[1;33m         \u001b[0mloglike\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mssm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloglike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;31m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fvirg\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py\u001b[0m in \u001b[0;36mloglike\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    999\u001b[0m         kwargs.setdefault('conserve_memory',\n\u001b[0;32m   1000\u001b[0m                           MEMORY_CONSERVE ^ MEMORY_NO_LIKELIHOOD)\n\u001b[1;32m-> 1001\u001b[1;33m         \u001b[0mkfilter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1002\u001b[0m         loglikelihood_burn = kwargs.get('loglikelihood_burn',\n\u001b[0;32m   1003\u001b[0m                                         self.loglikelihood_burn)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Apply VARMAX\n",
    "model = VARMAX(train_data.values, exog=None, order=(best_order_pq[0], best_order_pq[2]))\n",
    "model_fit = model.fit(maxiter=50, disp=True)\n",
    "print(model)\n",
    "print(model_fit)\n",
    "print(model_fit.params)\n",
    "print('\\n\\nCov matrix')\n",
    "cov_matrix = model_fit.cov_params()\n",
    "print(cov_matrix)\n",
    "\n",
    "parameters = model_fit.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_fit.predict(start=len(train_data), end=len(train_data) + len(test_data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_fit.save('varmax_model.pkl')\n",
    "\n",
    "# Reload the model\n",
    "#loaded_results = VARMAXResults.load('varmax_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_realized_vol(dataset, time):\n",
    "    #dataset['returns'] = np.log(dataset[\"Adj Close\"]/dataset[\"Adj Close\"].shift(1))\n",
    "    #dataset.fillna(0, inplace = True)\n",
    "    #window/time tells us how many days out vol you want. ~21 = 1 month out vol (~21 trading days in a month)\n",
    "    #we do this so we can match up with the vix which is the 30 day out (~21 trading day) calculated vol\n",
    "    volatility = dataset.returns.rolling(window=time).std(ddof=0)*np.sqrt(252)\n",
    "    return volatility\n",
    "    \n",
    "def get_realized_spx_vol(dataset, time):\n",
    "    #dataset['returns'] = np.log(dataset[\"Close\"]/dataset[\"Close\"].shift(1))\n",
    "    #dataset.fillna(0, inplace = True)\n",
    "    spx_volatility = dataset.returns.rolling(window=time).std(ddof=0)*np.sqrt(252)\n",
    "    return spx_volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast on the test set\n",
    "predictions2 = model_fit.forecast(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the target variable from the test set\n",
    "for column in train_data.columns:\n",
    "    actual_values = test_data[column]  # Adjust this based on your data\n",
    "\n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = mean_squared_error(actual_values, predictions2[column])  # Adjust the variable name based on your data\n",
    "\n",
    "    # Print the MAE\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
