{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x9w7HqI0uSfz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = 'data_feed/'\n",
    "# Set the hyperparameters\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_EPOCHS = 100\n",
    "LAG = 10\n",
    "N_STOCK = 20\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data_feed directory exist if not \n",
    "assert os.path.exists(BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all the files in the data_feed directory\n",
    "files = os.listdir('data_feed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df: pd.DataFrame, file_name: str) -> None:\n",
    "    \"\"\"\n",
    "    modify columns names (exept date) into the following structure: \n",
    "        *column_name*_*stock_name* \n",
    "        \n",
    "    Example: Open_AAPL\n",
    "    \"\"\"\n",
    "    df.rename(columns=dict(zip(df.columns[1:], df.columns[1:] + '_' + file_name[:-4])), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read First File into a pandas dataframe\n",
    "df = pd.read_csv(BASE_DIR+files[0])\n",
    "rename_columns(df, files[0])\n",
    "\n",
    "# Merge Everything into a unique DataFrame\n",
    "for fn in files[1:]:\n",
    "    df2 = pd.read_csv(BASE_DIR+fn)\n",
    "    rename_columns(df2, fn)\n",
    "    result = df.merge(df2, on='Date')\n",
    "    df = result\n",
    "\n",
    "df.set_index('Date',inplace=True)\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if \"Adj Close\" in col]\n",
    "df = df[cols]\n",
    "\n",
    "\n",
    "# Save all the data onto a file\n",
    "df.to_csv('AGGREGATED_DATA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy(deep=True)\n",
    "for col in df.columns:\n",
    "    df_copy[f'Ret_{col}'] = df_copy[col] / df_copy[col].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close_BRK-A</th>\n",
       "      <th>Adj Close_JPM</th>\n",
       "      <th>Adj Close_MCD</th>\n",
       "      <th>Adj Close_MSFT</th>\n",
       "      <th>Adj Close_MA</th>\n",
       "      <th>Adj Close_NKE</th>\n",
       "      <th>Adj Close_KO</th>\n",
       "      <th>Adj Close_V</th>\n",
       "      <th>Adj Close_UNH</th>\n",
       "      <th>Adj Close_HD</th>\n",
       "      <th>...</th>\n",
       "      <th>Ret_Adj Close_GOOGL</th>\n",
       "      <th>Ret_Adj Close_WMT</th>\n",
       "      <th>Ret_Adj Close_AAPL</th>\n",
       "      <th>Ret_Adj Close_PFE</th>\n",
       "      <th>Ret_Adj Close_META</th>\n",
       "      <th>Ret_Adj Close_XOM</th>\n",
       "      <th>Ret_Adj Close_PG</th>\n",
       "      <th>Ret_Adj Close_AMZN</th>\n",
       "      <th>Ret_Adj Close_DIS</th>\n",
       "      <th>Ret_Adj Close_JNJ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>139610.0</td>\n",
       "      <td>33.557884</td>\n",
       "      <td>67.764648</td>\n",
       "      <td>22.668226</td>\n",
       "      <td>47.946102</td>\n",
       "      <td>23.057142</td>\n",
       "      <td>27.239819</td>\n",
       "      <td>36.085690</td>\n",
       "      <td>46.601398</td>\n",
       "      <td>50.027027</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>140549.0</td>\n",
       "      <td>33.490253</td>\n",
       "      <td>68.148109</td>\n",
       "      <td>22.364561</td>\n",
       "      <td>48.014698</td>\n",
       "      <td>23.292871</td>\n",
       "      <td>27.239819</td>\n",
       "      <td>36.113567</td>\n",
       "      <td>44.422573</td>\n",
       "      <td>49.885166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000581</td>\n",
       "      <td>0.993645</td>\n",
       "      <td>0.987378</td>\n",
       "      <td>0.997685</td>\n",
       "      <td>0.991786</td>\n",
       "      <td>0.998197</td>\n",
       "      <td>0.993659</td>\n",
       "      <td>1.004547</td>\n",
       "      <td>1.002153</td>\n",
       "      <td>0.998588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>140803.0</td>\n",
       "      <td>34.083870</td>\n",
       "      <td>67.561600</td>\n",
       "      <td>21.945997</td>\n",
       "      <td>48.012821</td>\n",
       "      <td>23.519707</td>\n",
       "      <td>27.283293</td>\n",
       "      <td>36.408501</td>\n",
       "      <td>44.508015</td>\n",
       "      <td>49.790600</td>\n",
       "      <td>...</td>\n",
       "      <td>1.019760</td>\n",
       "      <td>1.003779</td>\n",
       "      <td>0.972146</td>\n",
       "      <td>1.004255</td>\n",
       "      <td>1.035650</td>\n",
       "      <td>1.004630</td>\n",
       "      <td>1.002031</td>\n",
       "      <td>1.002592</td>\n",
       "      <td>1.019137</td>\n",
       "      <td>1.011451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-07</th>\n",
       "      <td>140190.0</td>\n",
       "      <td>34.121441</td>\n",
       "      <td>68.358658</td>\n",
       "      <td>21.904963</td>\n",
       "      <td>48.844883</td>\n",
       "      <td>23.555288</td>\n",
       "      <td>27.022470</td>\n",
       "      <td>36.668633</td>\n",
       "      <td>44.508015</td>\n",
       "      <td>49.522652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995637</td>\n",
       "      <td>0.990443</td>\n",
       "      <td>0.994118</td>\n",
       "      <td>1.000771</td>\n",
       "      <td>1.022949</td>\n",
       "      <td>0.988422</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>1.035925</td>\n",
       "      <td>0.976624</td>\n",
       "      <td>0.997904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>141000.0</td>\n",
       "      <td>34.189060</td>\n",
       "      <td>68.381233</td>\n",
       "      <td>21.790056</td>\n",
       "      <td>48.684105</td>\n",
       "      <td>23.306211</td>\n",
       "      <td>26.834129</td>\n",
       "      <td>37.010017</td>\n",
       "      <td>43.918453</td>\n",
       "      <td>49.822124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998027</td>\n",
       "      <td>1.002778</td>\n",
       "      <td>1.002691</td>\n",
       "      <td>1.001539</td>\n",
       "      <td>0.987763</td>\n",
       "      <td>1.006255</td>\n",
       "      <td>0.998397</td>\n",
       "      <td>0.992252</td>\n",
       "      <td>0.995880</td>\n",
       "      <td>1.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>493000.0</td>\n",
       "      <td>136.050003</td>\n",
       "      <td>293.233490</td>\n",
       "      <td>309.433533</td>\n",
       "      <td>383.390015</td>\n",
       "      <td>121.819016</td>\n",
       "      <td>63.860001</td>\n",
       "      <td>231.009995</td>\n",
       "      <td>488.760010</td>\n",
       "      <td>285.633667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.043132</td>\n",
       "      <td>1.003736</td>\n",
       "      <td>1.001095</td>\n",
       "      <td>0.991818</td>\n",
       "      <td>1.011627</td>\n",
       "      <td>0.981901</td>\n",
       "      <td>1.002337</td>\n",
       "      <td>1.018060</td>\n",
       "      <td>0.912695</td>\n",
       "      <td>0.995917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-12</th>\n",
       "      <td>491182.0</td>\n",
       "      <td>134.100006</td>\n",
       "      <td>294.576355</td>\n",
       "      <td>308.296051</td>\n",
       "      <td>381.920013</td>\n",
       "      <td>119.815605</td>\n",
       "      <td>64.110001</td>\n",
       "      <td>231.380005</td>\n",
       "      <td>491.230011</td>\n",
       "      <td>288.393799</td>\n",
       "      <td>...</td>\n",
       "      <td>1.008064</td>\n",
       "      <td>0.999674</td>\n",
       "      <td>0.994582</td>\n",
       "      <td>0.993880</td>\n",
       "      <td>0.991603</td>\n",
       "      <td>0.999905</td>\n",
       "      <td>1.010169</td>\n",
       "      <td>0.982885</td>\n",
       "      <td>0.996533</td>\n",
       "      <td>0.998696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-15</th>\n",
       "      <td>495900.0</td>\n",
       "      <td>135.229996</td>\n",
       "      <td>294.337616</td>\n",
       "      <td>308.784973</td>\n",
       "      <td>383.410004</td>\n",
       "      <td>119.436852</td>\n",
       "      <td>63.939999</td>\n",
       "      <td>232.809998</td>\n",
       "      <td>486.859985</td>\n",
       "      <td>286.477600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991490</td>\n",
       "      <td>0.992226</td>\n",
       "      <td>0.997103</td>\n",
       "      <td>0.994913</td>\n",
       "      <td>1.021599</td>\n",
       "      <td>1.001907</td>\n",
       "      <td>1.000321</td>\n",
       "      <td>1.008525</td>\n",
       "      <td>1.009458</td>\n",
       "      <td>0.992350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-16</th>\n",
       "      <td>498620.0</td>\n",
       "      <td>134.320007</td>\n",
       "      <td>292.596832</td>\n",
       "      <td>311.059998</td>\n",
       "      <td>380.239990</td>\n",
       "      <td>116.097847</td>\n",
       "      <td>63.220001</td>\n",
       "      <td>230.470001</td>\n",
       "      <td>479.720001</td>\n",
       "      <td>280.311981</td>\n",
       "      <td>...</td>\n",
       "      <td>1.025749</td>\n",
       "      <td>0.986173</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995963</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>0.975730</td>\n",
       "      <td>0.998269</td>\n",
       "      <td>1.019784</td>\n",
       "      <td>0.979754</td>\n",
       "      <td>0.998684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-17</th>\n",
       "      <td>500600.0</td>\n",
       "      <td>138.449997</td>\n",
       "      <td>291.910492</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>116.596207</td>\n",
       "      <td>63.150002</td>\n",
       "      <td>232.649994</td>\n",
       "      <td>484.809998</td>\n",
       "      <td>290.300079</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011129</td>\n",
       "      <td>0.998331</td>\n",
       "      <td>1.003603</td>\n",
       "      <td>0.992975</td>\n",
       "      <td>1.015367</td>\n",
       "      <td>1.022435</td>\n",
       "      <td>0.995762</td>\n",
       "      <td>1.018519</td>\n",
       "      <td>1.019675</td>\n",
       "      <td>0.997804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2612 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Close_BRK-A  Adj Close_JPM  Adj Close_MCD  Adj Close_MSFT  \\\n",
       "Date                                                                        \n",
       "2013-01-02         139610.0      33.557884      67.764648       22.668226   \n",
       "2013-01-03         140549.0      33.490253      68.148109       22.364561   \n",
       "2013-01-04         140803.0      34.083870      67.561600       21.945997   \n",
       "2013-01-07         140190.0      34.121441      68.358658       21.904963   \n",
       "2013-01-08         141000.0      34.189060      68.381233       21.790056   \n",
       "...                     ...            ...            ...             ...   \n",
       "2023-05-11         493000.0     136.050003     293.233490      309.433533   \n",
       "2023-05-12         491182.0     134.100006     294.576355      308.296051   \n",
       "2023-05-15         495900.0     135.229996     294.337616      308.784973   \n",
       "2023-05-16         498620.0     134.320007     292.596832      311.059998   \n",
       "2023-05-17         500600.0     138.449997     291.910492      314.000000   \n",
       "\n",
       "            Adj Close_MA  Adj Close_NKE  Adj Close_KO  Adj Close_V  \\\n",
       "Date                                                                 \n",
       "2013-01-02     47.946102      23.057142     27.239819    36.085690   \n",
       "2013-01-03     48.014698      23.292871     27.239819    36.113567   \n",
       "2013-01-04     48.012821      23.519707     27.283293    36.408501   \n",
       "2013-01-07     48.844883      23.555288     27.022470    36.668633   \n",
       "2013-01-08     48.684105      23.306211     26.834129    37.010017   \n",
       "...                  ...            ...           ...          ...   \n",
       "2023-05-11    383.390015     121.819016     63.860001   231.009995   \n",
       "2023-05-12    381.920013     119.815605     64.110001   231.380005   \n",
       "2023-05-15    383.410004     119.436852     63.939999   232.809998   \n",
       "2023-05-16    380.239990     116.097847     63.220001   230.470001   \n",
       "2023-05-17    387.000000     116.596207     63.150002   232.649994   \n",
       "\n",
       "            Adj Close_UNH  Adj Close_HD  ...  Ret_Adj Close_GOOGL  \\\n",
       "Date                                     ...                        \n",
       "2013-01-02      46.601398     50.027027  ...                  NaN   \n",
       "2013-01-03      44.422573     49.885166  ...             1.000581   \n",
       "2013-01-04      44.508015     49.790600  ...             1.019760   \n",
       "2013-01-07      44.508015     49.522652  ...             0.995637   \n",
       "2013-01-08      43.918453     49.822124  ...             0.998027   \n",
       "...                   ...           ...  ...                  ...   \n",
       "2023-05-11     488.760010    285.633667  ...             1.043132   \n",
       "2023-05-12     491.230011    288.393799  ...             1.008064   \n",
       "2023-05-15     486.859985    286.477600  ...             0.991490   \n",
       "2023-05-16     479.720001    280.311981  ...             1.025749   \n",
       "2023-05-17     484.809998    290.300079  ...             1.011129   \n",
       "\n",
       "            Ret_Adj Close_WMT  Ret_Adj Close_AAPL  Ret_Adj Close_PFE  \\\n",
       "Date                                                                   \n",
       "2013-01-02                NaN                 NaN                NaN   \n",
       "2013-01-03           0.993645            0.987378           0.997685   \n",
       "2013-01-04           1.003779            0.972146           1.004255   \n",
       "2013-01-07           0.990443            0.994118           1.000771   \n",
       "2013-01-08           1.002778            1.002691           1.001539   \n",
       "...                       ...                 ...                ...   \n",
       "2023-05-11           1.003736            1.001095           0.991818   \n",
       "2023-05-12           0.999674            0.994582           0.993880   \n",
       "2023-05-15           0.992226            0.997103           0.994913   \n",
       "2023-05-16           0.986173            1.000000           0.995963   \n",
       "2023-05-17           0.998331            1.003603           0.992975   \n",
       "\n",
       "            Ret_Adj Close_META  Ret_Adj Close_XOM  Ret_Adj Close_PG  \\\n",
       "Date                                                                  \n",
       "2013-01-02                 NaN                NaN               NaN   \n",
       "2013-01-03            0.991786           0.998197          0.993659   \n",
       "2013-01-04            1.035650           1.004630          1.002031   \n",
       "2013-01-07            1.022949           0.988422          0.993197   \n",
       "2013-01-08            0.987763           1.006255          0.998397   \n",
       "...                        ...                ...               ...   \n",
       "2023-05-11            1.011627           0.981901          1.002337   \n",
       "2023-05-12            0.991603           0.999905          1.010169   \n",
       "2023-05-15            1.021599           1.001907          1.000321   \n",
       "2023-05-16            0.999833           0.975730          0.998269   \n",
       "2023-05-17            1.015367           1.022435          0.995762   \n",
       "\n",
       "            Ret_Adj Close_AMZN  Ret_Adj Close_DIS  Ret_Adj Close_JNJ  \n",
       "Date                                                                  \n",
       "2013-01-02                 NaN                NaN                NaN  \n",
       "2013-01-03            1.004547           1.002153           0.998588  \n",
       "2013-01-04            1.002592           1.019137           1.011451  \n",
       "2013-01-07            1.035925           0.976624           0.997904  \n",
       "2013-01-08            0.992252           0.995880           1.000140  \n",
       "...                        ...                ...                ...  \n",
       "2023-05-11            1.018060           0.912695           0.995917  \n",
       "2023-05-12            0.982885           0.996533           0.998696  \n",
       "2023-05-15            1.008525           1.009458           0.992350  \n",
       "2023-05-16            1.019784           0.979754           0.998684  \n",
       "2023-05-17            1.018519           1.019675           0.997804  \n",
       "\n",
       "[2612 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lgi6l4GkurA8"
   },
   "outputs": [],
   "source": [
    "split_date = df.index[0] + pd.offsets.DateOffset(years=8)\n",
    "train_data = df[df.index <= split_date]\n",
    "test_data = df[df.index > split_date]\n",
    "test_data.to_csv('TEST.csv')\n",
    "train_data.to_csv('TRAIN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preparation for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('TEST.csv')\n",
    "train_data = pd.read_csv('TRAIN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8l4tgxxudn0"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySA679S0yMUq"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(train_data.values)\n",
    "scaled_test = scaler.transform(test_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesdataset(Dataset):\n",
    "    def __init__(self, lag: int, data: np.ndarray, device: torch.device):\n",
    "        self.lag = lag\n",
    "        self.data = data\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        lenght = len(self.data)\n",
    "        return lenght - (self.lag + 1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx:idx+self.lag, :].flatten()\n",
    "        Y = self.data[idx+self.lag, :]\n",
    "        return torch.Tensor(X, device=self.device), torch.Tensor(Y, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_AgmYUmzesI"
   },
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesdataset(lag=LAG, data=scaled_train, device=device)\n",
    "test_dataset = TimeSeriesdataset(lag=LAG, data=scaled_test, device=device)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3SCXL1F27jmi"
   },
   "outputs": [],
   "source": [
    "# Create the RNN model\n",
    "model = RNN(input_size=LAG*N_STOCK, hidden_size=HIDDEN_SIZE, output_size=N_STOCK).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Tc6YKF-70M5",
    "outputId": "4ab96f85-5ebc-4dac-ad88-a89a01736431"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "running_loss = 0.\n",
    "last_loss = 0.\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        X, y = batch\n",
    "        predict = model(X)\n",
    "        loss = criterion(predict, y)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        last_loss = running_loss/10\n",
    "        print(f'Epoch: {epoch + 1}/{NUM_EPOCHS}, Loss: {last_loss}')\n",
    "        running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fw5M4zeD9LTx"
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "        X, y = batch\n",
    "        predict = model(X)\n",
    "        predictions.append(predict.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHDCSRC3B026"
   },
   "outputs": [],
   "source": [
    "# join everything into a unique matrix\n",
    "all_pred = np.zeros(N_STOCK)\n",
    "for b in predictions:\n",
    "    for p in b:\n",
    "        all_pred = np.vstack((all_pred, p))\n",
    "# Remove zero vector\n",
    "all_pred = all_pred[1:, :]\n",
    "all_pred = scaler.inverse_transform(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_real = np.concatenate((scaled_train, scaled_test))\n",
    "all_real = scaler.inverse_transform(all_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_real.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "for idx, file_name in enumerate(files):\n",
    "    stock = file_name[:-4]\n",
    "    index_test_start = all_real[:, 0].shape[0] - all_pred.shape[0]\n",
    "    plt.figure()\n",
    "    plt.plot( range(all_real.shape[0]) , all_real[:, idx], label='real')\n",
    "    plt.plot( range(index_test_start,all_real.shape[0]), all_pred[:, idx], color='orange', label='forecast')\n",
    "    plt.axvline(x=index_test_start, color='red', linestyle='--')\n",
    "    plt.title(stock)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
